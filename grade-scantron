#! /usr/bin/env python3

import sys
import re

if sys.version_info < (3,):
    # Python 3 is needed because Python 3's CSV module handles Unicode.
    raise RuntimeError("need Python 3!")

from codecs import open
from warnings import warn

# from warnings import warn

import logging
logger = logging.getLogger(__name__)


# {{{ copied from pytools

# {{{ elementary statistics

def average(iterable):
    """Return the average of the values in iterable.

    iterable may not be empty.
    """
    it = iterable.__iter__()

    try:
        sum = it.__next__()
        count = 1
    except StopIteration:
        raise ValueError("empty average")

    for value in it:
        sum = sum + value
        count += 1

    return sum/count


class VarianceAggregator:
    """Online variance calculator.
    See http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
    Adheres to pysqlite's aggregate interface.
    """
    def __init__(self, entire_pop):
        self.n = 0
        self.mean = 0
        self.m2 = 0

        self.entire_pop = entire_pop

    def step(self, x):
        self.n += 1
        delta = x - self.mean
        self.mean += delta/self.n
        self.m2 += delta*(x - self.mean)

    def finalize(self):
        if self.entire_pop:
            if self.n == 0:
                return None
            else:
                return self.m2/self.n
        else:
            if self.n <= 1:
                return None
            else:
                return self.m2/(self.n - 1)


def variance(iterable, entire_pop):
    v_comp = VarianceAggregator(entire_pop)

    for x in iterable:
        v_comp.step(x)

    return v_comp.finalize()


def std_deviation(iterable, finite_pop):
    from math import sqrt
    return sqrt(variance(iterable, finite_pop))

# }}}


def argmax2(iterable, return_value=False):
    it = iter(iterable)
    try:
        current_argmax, current_max = it.__next__()
    except StopIteration:
        raise ValueError("argmax of empty iterable")

    for arg, item in it:
        if item > current_max:
            current_argmax = arg
            current_max = item

    if return_value:
        return current_argmax, current_max
    else:
        return current_argmax


class Record(object):
    """An aggregate of named sub-variables. Assumes that each record sub-type
    will be individually derived from this class.
    """

    __slots__ = []

    def __init__(self, valuedict=None, exclude=["self"], **kwargs):
        assert self.__class__ is not Record

        try:
            fields = self.__class__.fields
        except AttributeError:
            self.__class__.fields = fields = set()

        if valuedict is not None:
            kwargs.update(valuedict)

        for key, value in kwargs.items():
            if key not in exclude:
                fields.add(key)
                setattr(self, key, value)

    def __repr__(self):
        return "%s(%s)" % (
            self.__class__.__name__,
            ", ".join(
                "%s=%r" % (fld, getattr(self, fld))
                for fld in self.__class__.fields
                if hasattr(self, fld)))


# {{{ histogram formatting

def string_histogram(
        iterable, min_value=None, max_value=None,
        bin_count=20, width=70, bin_starts=None, use_unicode=True):
    if bin_starts is None:
        if min_value is None or max_value is None:
            iterable = list(iterable)
            min_value = min(iterable)
            max_value = max(iterable)

        bin_width = (max_value - min_value)/bin_count
        bin_starts = [min_value+bin_width*i for i in range(bin_count)]

    bins = [0 for i in range(len(bin_starts))]

    from bisect import bisect
    for value in iterable:
        if (max_value is not None
                and value > max_value
                or value < bin_starts[0]):
            warn("string_histogram: out-of-bounds value ignored")
        else:
            bin_nr = bisect(bin_starts, value)-1
            try:
                bins[bin_nr] += 1
            except:
                print(value, bin_nr, bin_starts)
                raise

    from math import floor, ceil
    if use_unicode:
        def format_bar(cnt):
            scaled = cnt*width/max_count
            full = int(floor(scaled))
            eighths = int(ceil((scaled-full)*8))
            if eighths:
                return full*chr(0x2588) + chr(0x2588+(8-eighths))
            else:
                return full*chr(0x2588)
    else:
        def format_bar(cnt):
            return int(ceil(cnt*width/max_count))*"#"

    max_count = max(bins)
    total_count = sum(bins)
    return "\n".join("%9g |%9d | %3.0f %% | %s" % (
        bin_start,
        bin_value,
        bin_value/total_count*100,
        format_bar(bin_value))
        for bin_start, bin_value in zip(bin_starts, bins))

# }}}
# }}}


# {{{ data model

class ScantronExam(Record):
    """
    .. attribute:: last_name
    .. attribute:: initial
    .. attribute:: university_id
    .. attribute:: section
    .. attribute:: network_id
    .. attribute:: form_id
    .. attribute:: answers

        mapping from 1-based problem number to zero-based answer index

    .. attribute:: feedback_items
    .. attribute:: points_adjustment

        tuple of (delta, reason)
    """


class Problem(Record):
    """
    .. attribute:: number
    .. attribute:: title
    .. attribute:: correct_answers

        set of correct answers as set of 0-based numbers

    .. attribute:: is_dumped
    .. attribute:: tags
    """

    def __init__(self, number):
        Record.__init__(
            self,
            number=number,
            title="<no title>",
            correct_answers=set(),
            is_dumped=None,
            tags=set())


class FormData(object):
    """
    .. attribute:: form_id
    .. attribute:: problems

        map problem nr to Problem instance
    .. attribute:: full_score
    """

    def __init__(self, form_id, full_score=None):
        self.form_id = form_id
        self.problems = {}
        self.full_score = full_score

    def get_problem(self, problem_nr):
        return self.problems.setdefault(problem_nr, Problem(number=problem_nr))

    def dump_problem(self, problem_nr):
        """
        :arg problem_nr: 1-based
        """

        self.get_problem(problem_nr).is_dumped = True

    def add_correct_answer(self, problem_nr, answer_nr):
        """
        :arg problem_nr: 1-based
        :arg answer_nr: 0-based
        """

        self.get_problem(problem_nr).correct_answers.add(answer_nr)

    def add_tag(self, problem_nr, tag):
        """
        :arg problem_nr: 1-based
        """

        self.get_problem(problem_nr).tags.add(tag)


class GradeRecord(Record):
    """
    .. attribute:: exam
    .. attribute:: points
    .. attribute:: missed_problems
    .. attribute:: offset
    """


class MissedProblemRecord(Record):
    """
    .. attribute:: problem
    .. attribute:: your_answer
    """

# }}}


# {{{ parse

def parse_answer(answer, network_id, problem_nr, feedback_items):
    if answer == " ":
        return None

    try:
        # make 0-based
        answer = int(answer) - 1
    except ValueError:
        warn(
            "student '%s' checked multiple answers on problem "
            "%d (scantron mark '%s')" % (
                network_id,
                problem_nr,
                answer))

        feedback_items.append(
            "Checked multiple answers on P%d" % problem_nr)

        return None

    assert 0 <= answer <= 5

    return answer


def read_scantron_file(exams, lines, options):
    for l in lines:
        if not l.strip():
            continue
        if len(l) == 1:
            continue
        if len(l) != 174:
            raise ValueError("invalid record length: %d" % len(l))

        feedback_items = []

        network_id = l[63:71].lower().strip()
        last_name = l[40:50].rstrip()

        exam = ScantronExam(
            last_name=last_name,
            initial=l[50],
            university_id=l[51:60],
            section=l[60:63],
            network_id=network_id,
            form_id=l[71],
            answers={
                pnr+1: parse_answer(
                    a, network_id, pnr+1,
                    feedback_items)
                for pnr, a in enumerate(l[72:168])
                },
            feedback_items=feedback_items,
            points_adjustment=None
            )

        if any(exam.network_id == network_id for exam in exams):
            logger.warn(
                "duplicate network ID '%s' in scantron data (last name '%s')"
                % (network_id, last_name))

        exams.append(exam)


def read_yaml_file(exams, yml_data, options):
    for yml_entry in yml_data:
        network_id = yml_entry["network_id"]
        exams_to_update = [
            exam
            for exam in exams
            if exam.network_id == network_id]

        is_new = len(exams_to_update) == 0
        if is_new:
            exam = ScantronExam(network_id=network_id)
            exams.append(exam)
        elif len(exams_to_update) > 1:
            raise RuntimeError(
                "%d exams match network id '%s'--canot update"
                % (len(exams_to_update), network_id))
        else:
            exam, = exams_to_update

        def copy_if_present(field, optional, default=None):
            if field not in yml_entry:
                if is_new:
                    if not optional:
                        raise RuntimeError(
                            "YAML entry '%s' is missing field '%s'"
                            % (network_id, field))
                    else:
                        setattr(exam, field, default)

                return

            if not is_new:
                logger.info(
                    "updating field '%s' exam for network id '%s' from YAML"
                    % (field, network_id))

            value = yml_entry[field]
            if field == "answers":
                value = {
                    problem_nr: ord(a) - ord("A")
                    for problem_nr, a in value.items()
                    }
                if hasattr(exam, "answers"):
                    exam.answers.update(value)
                else:
                    setattr(exam, field, value)
            else:
                setattr(exam, field, value)

        copy_if_present("last_name", optional=False)
        copy_if_present("initial", optional=False)
        copy_if_present("university_id", optional=True)
        copy_if_present("section", optional=True)
        copy_if_present("form_id", optional=False)
        copy_if_present("answers", optional=False)
        copy_if_present("feedback_items", optional=True, default=[])
        copy_if_present("points_adjustment", optional=True)

# }}}


# {{{ key handling

def separate_out_keys(exams):
    scantron_keys = {}

    new_exams = []

    for s in exams:
        if (s.last_name.rstrip() == "KEY"
                and s.university_id.startswith("99999999")):
            if s.form_id in scantron_keys:
                raise ValueError("two keys for form id '%s'" % s.form_id)
            scantron_keys[s.form_id] = s
        else:
            new_exams.append(s)

    return new_exams, scantron_keys


def read_latex_key(name, inf, get_form):
    version_re = re.compile("^version: (.+)$")
    problem_re = re.compile("^problem ([0-9]+): (.+)$")
    problem_tag_re = re.compile("^problem tag ([0-9]+): (.+)$")
    title_re = re.compile("^title ([0-9]+):(.*)$")

    lines = list(inf)

    version_match = version_re.match(lines[0])
    if version_match is None:
        raise RuntimeError("version line not found in '%s'" % name)
    form_id = version_match.group(1)
    lines = lines[1:]

    form = get_form(form_id)
    for l in lines:
        problem_match = problem_re.match(l)
        problem_tag_match = problem_tag_re.match(l)
        title_match = title_re.match(l)

        if problem_match:
            problem_nr = int(problem_match.group(1))
            action = problem_match.group(2)

            if action == "dump":
                form.dump_problem(problem_nr)
            else:
                assert len(action) == 1
                answer = ord(action) - ord("A")

                form.add_correct_answer(problem_nr, answer)
        elif problem_tag_match:
            problem_nr = int(problem_tag_match.group(1))
            tag = problem_tag_match.group(2)

            form.add_tag(problem_nr, tag)
        elif title_match:
            problem_nr = int(title_match.group(1))
            form.get_problem(problem_nr).title = title_match.group(2).strip()
        else:
            raise RuntimeError(
                "invalid line found in '%s': %s"
                % (name, l))

    if form.full_score is None:
        form.full_score = sum(
            1
            for p in form.problems.values()
            if p.correct_answers)

# }}}


def get_grade_rec(exam, form, options):
    grade_recs = {}

    for offset in options.try_offsets:
        points = options.bonus
        missed_problems = []

        if not form.problems:
            raise RuntimeError(
                "form version '%s' has no known correct answers"
                % (form.form_id))

        if not exam.answers:
            raise RuntimeError(
                "exam '%s' has no answers at all"
                % (exam.network_id))

        highest_numbered_problem = max(
            max(exam.answers),
            max(form.problems))

        if exam.points_adjustment is not None:
            delta, _ = exam.points_adjustment
            points += delta
            del delta

        for problem_nr in range(1, highest_numbered_problem+1):
            answer = exam.answers.get(problem_nr)

            try:
                problem = form.problems[problem_nr+offset]
            except KeyError:
                if answer is not None and not offset:
                    warn(
                        "student '%s' answered unknown problem "
                        "'%d' with '%s'" % (
                            exam.network_id,
                            problem_nr,
                            answer))

                continue

            if problem.is_dumped:
                points += 1
                continue

            correct_answers = problem.correct_answers
            if answer in correct_answers:
                points += 1
            else:
                missed_problems.append(
                    MissedProblemRecord(
                        problem=problem,
                        your_answer=answer))

        grade_recs[offset] = GradeRecord(
            exam=exam,
            points=points,
            missed_problems=missed_problems,
            offset=offset,
            )

    best_result = argmax2(
        (grade_rec, grade_rec.points)
        for grade_rec in grade_recs.values())

    if best_result.points > grade_recs[0].points:
        logger.info(
            "improved result with offset for %s: %d vs %d"
            % (exam.network_id, best_result.points, grade_recs[0].points))

    return best_result


def stringify_answer(answer):
    if answer is None:
        return "<no answer>"
    else:
        return chr(65+answer)


def shorten_title(title):
    if len(title) > 10:
        return title[:10]+u'\u2026'
    else:
        return title


def print_problem_analytics(forms, exams):
    for form_id in sorted(forms):
        print(75*"-")
        print("FORM %s" % form_id)
        print(75*"-")
        form = forms[form_id]
        for problem_nr in sorted(
                list(form.problems.keys())
                ):
            answer_freqs = {}
            total_answers = 0

            problem = form.problems[problem_nr]

            for e in exams:
                if e.form_id != form_id:
                    continue

                answer = e.answers.get(problem_nr)
                if answer is not None:
                    total_answers += 1

                answer_freqs[answer] = answer_freqs.get(answer, 0) + 1

            if problem.is_dumped:
                print("Form %s Question %d: UNGRADED" % (
                    form_id, problem_nr))
                continue

            if total_answers == 0:
                print("Form %s Question %d: NO ANSWERS (%s)" % (
                    form_id, problem_nr, problem.title))
                continue

            if problem.correct_answers:
                corr_str = ", ".join(
                    "%s: %2.0f%%=%d" % (
                        stringify_answer(answer),
                        100*answer_freqs.get(answer, 0)/total_answers,
                        answer_freqs.get(answer, 0))
                    for answer in problem.correct_answers)
            else:
                corr_str = "<no correct answers>"

            incorr_str = ", ".join(
                "%s: %2.0f%%=%d" % (
                    stringify_answer(answer),
                    100*answer_freqs.get(answer, 0)/total_answers,
                    answer_freqs.get(answer, 0))
                for answer in sorted(
                    answer_freqs,
                    key=lambda answer: answer_freqs[answer],
                    reverse=True)
                if answer not in problem.correct_answers)

            print("Form %s Question %d: [[ %s ]] %s (%s)" % (
                form_id, problem_nr, corr_str, incorr_str, problem.title))


def get_export_points_and_feedback(grade_rec, forms, options):
    points = grade_rec.points
    feedback_items = grade_rec.exam.feedback_items[:]

    feedback_items.append("Form %s" % grade_rec.exam.form_id)
    form = forms[grade_rec.exam.form_id]

    if grade_rec.missed_problems:
        feedback_items.append(
            "Incorrect: "
            + " - ".join(
                "P%d: %s (OK: %s - %s)"
                % (mpr.problem.number,
                    stringify_answer(mpr.your_answer),
                    "".join(
                        stringify_answer(ans)
                        for ans in mpr.problem.correct_answers),
                    #shorten_title(mpr.problem.title))
                    mpr.problem.title)
                for mpr in grade_rec.missed_problems
                if mpr.problem.correct_answers)
            )
    else:
        feedback_items.append("All answers correct.")

    if grade_rec.exam.points_adjustment is not None:
        delta, reason = grade_rec.exam.points_adjustment

        if delta > 0:
            feedback_items.append(
                "%d point(s) added for '%s'"
                % (delta, reason)
                )
        elif delta < 0:
            feedback_items.append(
                "%d point(s) subtracted for '%s'"
                % (-delta, reason)
                )

        del delta
        del reason

    if options.cap and points > options.cap:
        feedback_items.append(
            "Achieved points: %d. Extra credit capped to: %d/%d."
            % (points, options.cap, form.full_score))
        points = options.cap

    if grade_rec.offset:
        feedback_items.append(
            "Offset was applied. Form Q1 -> Exam Q%d"
            % (1+grade_rec.offset))

    return points, feedback_items


def main():
    from optparse import OptionParser
    parser = OptionParser(usage="%prog [options] DAT_FILES")

    parser.add_option("--debug", action="store_true")
    parser.add_option(
        "--latex-key", help="Add a LaTeX-generated key data file",
        metavar="FILE", action="append")
    parser.add_option(
        "--bonus", help="Add free bonus points",
        metavar="POINTS", type=int, default=0)
    parser.add_option(
        "--full-score", help="Set full score for determining percentages",
        metavar="POINTS", type=int)
    parser.add_option(
        "--cap", help="Don't propagate more than this "
        "number of points to grade export",
        metavar="POINTS", type=int)
    parser.add_option(
        "--try-offsets", help="Try a few offsets for Scantron grading "
        "(should include 0)",
        metavar="OFFSET,OFFSET")

    parser.add_option("--print-grades", action="store_true")
    parser.add_option("--print-stats", action="store_true")
    parser.add_option("--no-form-stats", action="store_true")
    parser.add_option("--print-problem-analytics", action="store_true")
    parser.add_option("--write-csv", metavar="FILE")
    parser.add_option("--print-student-report", metavar="NETWORK_ID")

    options, args = parser.parse_args()

    if not args:
        parser.print_help()
        sys.exit(1)

    if options.debug:
        logging.basicConfig(level=logging.INFO)

    if options.try_offsets is not None:
        options.try_offsets = [int(o) for o in options.try_offsets.split(",")]
        assert 0 in options.try_offsets
    else:
        options.try_offsets = [0]

    exams = []
    for arg in args:
        with open(arg, "rt") as inf:
            if arg.endswith(".dat") or arg.endswith(".DAT"):
                read_scantron_file(exams, inf, options)
            elif arg.endswith(".yaml") or arg.endswith(".yml"):
                import yaml
                read_yaml_file(exams, yaml.load(inf), options)

    # {{{ figure out form versions

    form_ids = sorted(
        set(s.form_id for s in exams)
        |
        set(s.form_id for s in exams)
        )

    forms = {}

    def get_form(form_id):
        try:
            return forms[form_id]
        except KeyError:
            forms[form_id] = form = FormData(form_id, full_score=options.full_score)
            return form

    for form_id in form_ids:
        get_form(form_id)

    # }}}

    # {{{ handle scantron keys

    exams, scantron_keys = separate_out_keys(exams)

    logger.info("%d scantron keys found: %s" % (
        len(scantron_keys), sorted(scantron_keys.keys())))

    # }}}

    # {{{ handle latex keys

    if options.latex_key is not None:
        for fn in options.latex_key:
            with open(fn, "rt") as inf:
                read_latex_key(fn, inf, get_form)

        for form_id, key in scantron_keys.items():
            grade_rec = get_grade_rec(key, get_form(key.form_id), options)
            logger.info("scantron key for form '%s' received %d points" % (
                form_id, grade_rec.points))

    # }}}

    logger.info("%d form versions found: %s" % (
        len(form_ids), form_ids))

    if options.print_stats:
        point_counts = []
        form_point_counts = {}
        for e in exams:
            grade_rec = get_grade_rec(e, forms[e.form_id], options)
            point_counts.append(grade_rec.points)
            form_point_counts.setdefault(e.form_id, []) \
                .append(grade_rec.points)

        print(string_histogram(
            point_counts,
            min_value=0, max_value=(max(point_counts)), bin_count=15,
            width=30))

        print()
        print("Mean: %f" % (average(point_counts)))
        print("Std deviation: %f" % (std_deviation(point_counts, False)))
        print()
        if not options.no_form_stats:
            for form_id in sorted(form_point_counts):
                print("Form %s mean: %f" % (
                    form_id, average(form_point_counts[form_id])))

    if options.print_grades:
        for e in exams:
            form = forms[e.form_id]
            grade_rec = get_grade_rec(e, form, options)
            print("%-20s | %-10s | % 6.1f %% | % 3d points" % (
                e.last_name + ", " + e.initial, e.network_id,
                grade_rec.points/form.full_score*100, grade_rec.points))

    if options.print_problem_analytics:
        print_problem_analytics(forms, exams)

    if options.write_csv:
        import csv
        with open(options.write_csv, 'wb', encoding="utf-8") as csvfile:
            csvwriter = csv.writer(csvfile)
            csvwriter.writerow(
                ["NetID", "Last Name", "Initial", "Points", "Feedback"])

            for e in exams:
                grade_rec = get_grade_rec(e, forms[e.form_id], options)

                points, feedback_items = \
                    get_export_points_and_feedback(grade_rec, forms, options)

                csvwriter.writerow(
                    [e.network_id, e.last_name, e.initial,
                        points, u" * ".join(feedback_items)])

    if options.print_student_report:
        for e in exams:
            if e.network_id.lower() == options.print_student_report.lower():
                grade_rec = get_grade_rec(e, forms[e.form_id], options)

                points, feedback_items = \
                    get_export_points_and_feedback(grade_rec, forms, options)

                for fbi in feedback_items:
                    print(fbi)

                print()
                print("Name: %s, %s" % (e.last_name, e.initial))
                print("Points: %d" % points)

if __name__ == "__main__":
    main()

# vim: foldmethod=marker
